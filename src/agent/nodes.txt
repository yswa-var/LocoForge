"""Node definitions for the agent graph."""

from typing import Dict, Any, List
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
import json
import logging
import asyncio
from functools import partial
import sqlite3
from contextlib import contextmanager

from .sql_agent import SQLAgent
from .no_sql_agent import GeneralizedNoSQLAgent

logger = logging.getLogger(__name__)


def get_llm(config: Configuration) -> ChatOpenAI:
    """Initialize and return the LLM with configuration."""
    return ChatOpenAI(
        model=config.get("model_name", "gpt-3.5-turbo"),
        temperature=config.get("temperature", 0.7),
        api_key=os.getenv("OPENAI_API_KEY")
    )


@contextmanager
def get_sqlite_connection(db_path: str):
    """Context manager for SQLite connections."""
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()


def get_table_schema(db_path: str) -> str:
    """Get the schema of the database tables."""
    with get_sqlite_connection(db_path) as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT sql FROM sqlite_master WHERE type='table'")
        schemas = cursor.fetchall()
        return "\n".join([schema[0] for schema in schemas])


async def get_mongo_schema() -> Dict[str, Any]:
    """Get MongoDB schema in a thread-safe way."""
    try:
        nosql_agent = GeneralizedNoSQLAgent()
        await nosql_agent.initialize()
        available_dbs = await nosql_agent.list_databases()
        
        # Filter out system databases
        user_dbs = [db for db in available_dbs if db not in ['admin', 'local', 'config']]
        
        if not user_dbs:
            logger.warning("No user databases found, using default database")
            db_name = "user_management_db"
        else:
            db_name = user_dbs[0]
            
        logger.info(f"Using database: {db_name}")
        await nosql_agent.use_database(db_name)
        
        # Get all collections in the database
        collections = await nosql_agent.list_collections()
        schemas = {}
        
        # Get schema for each collection
        for collection in collections:
            if collection not in ['system.version', 'system.indexes']:
                collection_schema = await nosql_agent.get_collection_schema(collection)
                if collection_schema:
                    schemas[collection] = collection_schema
        
        await nosql_agent.close()
        return schemas
    except Exception as e:
        logger.error(f"Error getting MongoDB schema: {str(e)}", exc_info=True)
        return {}


async def get_schema_context():
    """Get the schema context from both SQL and NoSQL databases."""
    try:
        # Get SQL schema
        db_path = os.path.join(os.path.dirname(__file__), "sales.db")
        logger.info(f"Attempting to connect to SQL database at: {db_path}")
        
        # Get SQL schema in a thread-safe way
        sql_schema = await asyncio.to_thread(get_table_schema, db_path)

        # Get MongoDB schema directly since it's already async
        logger.info("Attempting to connect to MongoDB")
        nosql_schemas = await get_mongo_schema()

        return {
            "sql_schema": sql_schema,
            "nosql_schemas": nosql_schemas
        }
    except Exception as e:
        logger.error(f"Error getting schema context: {str(e)}", exc_info=True)
        return {
            "sql_schema": "Error retrieving SQL schema",
            "nosql_schemas": "Error retrieving NoSQL schemas",
            "error": str(e)
        }


async def supervisor_node(state: InputState, config: RunnableConfig) -> Dict[str, Any]:
    """Supervisor node that analyzes user query and creates structured tasks for agents."""
    try:
        # Get the last message and schema context
        if not state.get("messages"):
            return {
                "messages": [
                    {
                        "role": "assistant",
                        "content": json.dumps({
                            "status": "error",
                            "error": "No messages found in state",
                            "retry_count": 0
                        }, indent=2)
                    }
                ]
            }

        # Handle both string and list message formats
        if isinstance(state["messages"], str):
            last_message = state["messages"]
        elif isinstance(state["messages"], list):
            if not state["messages"]:
                return {
                    "messages": [
                        {
                            "role": "assistant",
                            "content": json.dumps({
                                "status": "error",
                                "error": "Empty messages list",
                                "retry_count": 0
                            }, indent=2)
                        }
                    ]
                }
            last_message = state["messages"][-1].get("content", "")
        else:
            return {
                "messages": [
                    {
                        "role": "assistant",
                        "content": json.dumps({
                            "status": "error",
                            "error": f"Invalid message format: {type(state['messages'])}",
                            "retry_count": 0
                        }, indent=2)
                    }
                ]
            }

        schema_context = await get_schema_context()
        
        # Create a prompt for the LLM to analyze the query and create structured tasks
        system_prompt = f"""You are a smart data analysis expert. Analyze the user's query and determine what data needs to be gathered from SQL and NoSQL databases.

Available Database Schemas:
SQL Schema:
{schema_context.get('sql_schema', 'No SQL schema available')}

NoSQL Schema:
{schema_context.get('nosql_schemas', 'No NoSQL schema available')}

User Query: {last_message}

Your task is to:
1. Analyze the query to determine if it requires data from SQL, NoSQL, or both databases
2. Pay special attention to queries that explicitly mention "no_sql", "mongodb", or "nosql" - these should be routed to the specified agent
3. Create appropriate tasks for each required database type
4. For taskDefinition about "all tables" or "all data", you MUST create tasks for both SQL and NoSQL databases
5. Assign priorities based on the logical order of operations (e.g., if NoSQL data depends on SQL data, SQL task gets higher priority)
6. Determine the preferred agent based on the query requirements

IMPORTANT RULES:
- If the query explicitly mentions "no_sql", "mongodb", or "nosql", it MUST be routed to the NoSQL agent
- If the query is about document-based data or unstructured data, prefer the NoSQL agent
- If the query is about relational data with clear table relationships, prefer the SQL agent
- If the query mentions both types of data, create tasks for both but specify the preferred agent

Respond with a JSON object in this format:
{{
    "tasks": [
        {{
            "agent": "sql_agent" or "nosql_agent" or "drive_agent",
            "taskDefinition": "a clear description of the task for which a query is needed",
            "purpose": "brief explanation of why this query is needed",
            "priority": 1-5,  # Higher number means higher priority
            "dependencies": ["list of task indices this task depends on"]
        }}
    ],
    "context": {{
        "required_data": ["list of data points needed"],
        "relationships": ["how the data points relate to each other"],
        "error_handling": {{
            "retry_count": 3,
            "fallback_strategy": "description of fallback approach"
        }}
    }},
    "preferred_agent": "sql_agent" or "nosql_agent" or null  # Specify if there's a clear preference
}}"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": last_message}
        ]
        
        # Initialize LLM with config
        llm = get_llm(config)
        print("--------------------------------")
        print(system_prompt)
        print("--------------------------------")
        
        # Move LLM call to a separate thread
        response = await asyncio.to_thread(llm.invoke, messages)
        task_analysis = json.loads(response.content)
        
        # Sort tasks by priority
        sorted_tasks = sorted(task_analysis["tasks"], key=lambda x: x["priority"], reverse=True)
        
        # Create the output state with messages
        output_state = {
            "messages": [
                {
                    "role": "assistant",
                    "content": json.dumps({
                        "tasks": sorted_tasks,
                        "context": task_analysis["context"],
                        "current_task_index": 0,
                        "error_handling": task_analysis["context"]["error_handling"],
                        "analysis": {
                            "total_tasks": len(sorted_tasks),
                            "task_types": list(set(task["agent"] for task in sorted_tasks)),
                            "highest_priority_task": sorted_tasks[0] if sorted_tasks else None
                        },
                        "preferred_agent": task_analysis.get("preferred_agent")
                    }, indent=2)
                }
            ]
        }
        
        return output_state
    except Exception as e:
        logger.error(f"Error in supervisor_node: {str(e)}", exc_info=True)
        return {
            "messages": [
                {
                    "role": "assistant",
                    "content": json.dumps({
                        "status": "error",
                        "error": f"Failed to analyze query: {str(e)}",
                        "retry_count": 0
                    }, indent=2)
                }
            ]
        }


